{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HDUL OKUMA ######\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "# Specify the path to your FITS file\n",
    "fits_file_path = '/Users/nurullah/Desktop/true_PNe/sn/sn/png021.3+02.2.txt_lines1.fits'\n",
    "# Open the FITS file\n",
    "with fits.open(fits_file_path) as hdul:\n",
    "    # Access the data in the FITS file\n",
    "    primary_hdu = hdul[1]\n",
    "    data = primary_hdu.data\n",
    "    \n",
    "with fits.open(fits_file_path) as hdul:\n",
    "    hdul.info()\n",
    "\n",
    "    # Print the transposed data\n",
    "    print(\"\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b21ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "# Specify the path to your FITS file\n",
    "fits_file_path = '/Users/nurullah/Desktop/true_PNe/sn/latexçıktı/neat_fits_çıktı/apng216.fits_fit.fits'\n",
    "\n",
    "# Open the FITS file\n",
    "with fits.open(fits_file_path) as hdul:\n",
    "    # You can access the data in the FITS file\n",
    "    # For example, printing the information about the FITS file:\n",
    "    hdul.info()\n",
    "    \n",
    "    # You can access different HDU (Header Data Unit) in the FITS file\n",
    "    # For example, to access the primary HDU (usually the first one):\n",
    "    primary_hdu = hdul[4]\n",
    "\n",
    "    # You can access the data and header of the primary HDU\n",
    "    data = primary_hdu.data\n",
    "    header = primary_hdu.header\n",
    "\n",
    "    # You can also print the header and data to see the details\n",
    "    print(\"Header:\")\n",
    "    print(repr(header))\n",
    "    print(\"Data:\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GDPNE klasöründe bulunan alt klasörlerdeki fits dosyalarını tek bir klasöre kaydetme ###\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def klasorleri_birlestir(ana_klasor, hedef_klasor):\n",
    "    if not os.path.exists(hedef_klasor):\n",
    "        os.makedirs(hedef_klasor)\n",
    "\n",
    "    for root, dirs, files in os.walk(ana_klasor):\n",
    "        for file in files:\n",
    "            if file.endswith('.fits'):\n",
    "                dosya_yolu = os.path.join(root, file)\n",
    "                shutil.copy2(dosya_yolu, hedef_klasor)\n",
    "\n",
    "    print(f'Tüm .fits dosyaları {hedef_klasor} klasörüne kopyalandı.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ana_klasor = \"/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/GPNE/\"  # Ana klasörünüzün yolunu belirtin\n",
    "    cikti_dosyasi = \"/Users/nurullah/Desktop/galaxy_abudance/sigma_karşılaştırma/\"  # Çıktı dosyasının adını ve yolunu belirtin\n",
    "\n",
    "    klasorleri_birlestir(ana_klasor, cikti_dosyasi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554dd0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Dizin içindeki tüm FITS dosyalarını al\n",
    "fits_directory = '/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/sigma_5/bilgiislem/neat_out/'\n",
    "fits_file_paths = [os.path.join(fits_directory, file) for file in sorted(os.listdir(fits_directory)) if file.endswith('.fits')]\n",
    "\n",
    "# Excel dosyalarının kaydedileceği dizin\n",
    "output_directory = '/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/sigma_5/bilgiislem/deneme/'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Her 50 FITS dosyası için ayrı bir Excel dosyası oluştur\n",
    "batch_size = 50\n",
    "\n",
    "# Dosya isimlerini saklayacak bir sözlük oluştur\n",
    "file_names_dict = {}\n",
    "\n",
    "for i in range(0, len(fits_file_paths), batch_size):\n",
    "    batch_fits_files = fits_file_paths[i:i + batch_size]\n",
    "\n",
    "    # Excel dosyasının ismini belirle\n",
    "    excel_file_name = f'batch_{i // batch_size + 1}.xlsx'\n",
    "    excel_file_path = os.path.join(output_directory, excel_file_name)\n",
    "\n",
    "    # Her FITS dosyası için döngü\n",
    "    with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:\n",
    "        for fits_file_path in batch_fits_files:\n",
    "            # Open the FITS file\n",
    "            with fits.open(fits_file_path) as hdul:\n",
    "                # Access the data and header of the LINES BinTableHDU (hdul[2])\n",
    "                data = hdul[1].data\n",
    "\n",
    "                # Convert the FITS data to a pandas DataFrame\n",
    "                df = pd.DataFrame(data)\n",
    "\n",
    "                # Sadece belirtilen sütunları seç\n",
    "                selected_columns = ['WlenRest', 'Flux', 'Uncertainty', 'Ion', 'DereddenedFlux', 'DereddenedFluxLo', 'DereddenedFluxHi']\n",
    "                df_selected = df[selected_columns]\n",
    "\n",
    "                # Negatif ve sıfıra eşit olan değerlere sahip satırları filtrele ve sil\n",
    "                df_selected = df_selected[df_selected['Flux'] > 0.01]\n",
    "\n",
    "                # Sayfa adını dosya isminin ilk 31 karakteri olarak ayarla\n",
    "                sheet_name = os.path.basename(fits_file_path)[:31]\n",
    "                \n",
    "                # Tam dosya ismini sözlüğe ekle\n",
    "                file_names_dict[sheet_name] = os.path.basename(fits_file_path)\n",
    "\n",
    "                # Verileri içeren DataFrame'i yeni bir sayfada kaydet\n",
    "                df_selected.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"Data has been successfully exported to {excel_file_path}\")\n",
    "\n",
    "# Dosya isimlerini bir CSV dosyasına kaydedelim\n",
    "file_names_dict_path = os.path.join(output_directory, 'file_names_dict.csv')\n",
    "file_names_df = pd.DataFrame(list(file_names_dict.items()), columns=['SheetName', 'FullFileName'])\n",
    "file_names_df.to_csv(file_names_dict_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Excel dosyalarının bulunduğu klasörün tam yolu\n",
    "excel_folder_path = '/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/sigma_5/bilgiislem/deneme/'\n",
    "\n",
    "# Tüm Excel dosyalarını al\n",
    "excel_files = [os.path.join(excel_folder_path, file) for file in sorted(os.listdir(excel_folder_path)) if file.endswith('.xlsx')]\n",
    "\n",
    "# Dosya isimleri sözlüğünü oku\n",
    "file_names_dict_path = os.path.join(excel_folder_path, 'file_names_dict.csv')\n",
    "file_names_df = pd.read_csv(file_names_dict_path)\n",
    "file_names_dict = dict(zip(file_names_df['SheetName'], file_names_df['FullFileName']))\n",
    "\n",
    "# Birleştirilecek verileri tutacak ana DataFrame'i oluştur\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "# Her Excel dosyası için döngü\n",
    "for excel_file_path in excel_files:\n",
    "    # Excel dosyasını oku\n",
    "    df = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "\n",
    "    # Her sayfa için döngü\n",
    "    for sheet_name, sheet_data in df.items():\n",
    "        # 'WlenRest', 'Ion', 'Flux' sütunlarını içeren sayfaları seç\n",
    "        if all(col in sheet_data.columns for col in ['WlenRest', 'Ion', 'Flux']):\n",
    "            full_file_name = file_names_dict.get(sheet_name, sheet_name)\n",
    "            # Eğer ana DataFrame boşsa, direkt ekle\n",
    "            if main_df.empty:\n",
    "                main_df = sheet_data[['WlenRest', 'Ion', 'Flux']].copy()\n",
    "                main_df.rename(columns={'Flux': f'Flux_{full_file_name}'}, inplace=True)\n",
    "            else:\n",
    "                # Ana DataFrame'de 'WlenRest' ve 'Ion' sütunlarına göre birleştirme yap\n",
    "                main_df = main_df.merge(sheet_data[['WlenRest', 'Ion', 'Flux']],\n",
    "                                        on=['WlenRest', 'Ion'],\n",
    "                                        how='outer',\n",
    "                                        suffixes=('', f'_{full_file_name}'))\n",
    "\n",
    "# NaN değerleri '-' ile değiştir\n",
    "main_df.fillna('-', inplace=True)\n",
    "\n",
    "# 'WlenRest' sütununa göre küçükten büyüğe sırala\n",
    "main_df.sort_values('WlenRest', inplace=True)\n",
    "\n",
    "# Excel dosyasına ekleyeceğimiz sayfa adı\n",
    "new_sheet_name = 'Flux_Tablo'\n",
    "\n",
    "# Yeni bir Excel dosyası oluştur\n",
    "output_excel_file_path = '/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/sigma_5/bilgiislem/deneme/Fluxtablo.xlsx'\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='openpyxl') as writer:\n",
    "    main_df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "print(f\"Merged, sorted data has been successfully added to the sheet {new_sheet_name} in the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bf56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Excel dosyalarının bulunduğu klasörün tam yolu\n",
    "excel_folder_path = '/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/sigma_5/bilgiislem/deneme/'\n",
    "\n",
    "# Tüm Excel dosyalarını al\n",
    "excel_files = [os.path.join(excel_folder_path, file) for file in sorted(os.listdir(excel_folder_path)) if file.endswith('.xlsx')]\n",
    "\n",
    "# Dosya isimleri sözlüğünü oku\n",
    "file_names_dict_path = os.path.join(excel_folder_path, 'file_names_dict.csv')\n",
    "file_names_df = pd.read_csv(file_names_dict_path)\n",
    "file_names_dict = dict(zip(file_names_df['SheetName'], file_names_df['FullFileName']))\n",
    "\n",
    "# Birleştirilecek verileri tutacak ana DataFrame'i oluştur\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "# Her Excel dosyası için döngü\n",
    "for excel_file_path in excel_files:\n",
    "    # Excel dosyasını oku\n",
    "    df = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "\n",
    "    # Her sayfa için döngü\n",
    "    for sheet_name, sheet_data in df.items():\n",
    "        # 'WlenRest', 'Ion', 'DereddenedFlux' sütunlarını içeren sayfaları seç\n",
    "        if all(col in sheet_data.columns for col in ['WlenRest', 'Ion', 'DereddenedFlux']):\n",
    "            full_file_name = file_names_dict.get(sheet_name, sheet_name)\n",
    "            # Eğer ana DataFrame boşsa, direkt ekle\n",
    "            if main_df.empty:\n",
    "                main_df = sheet_data[['WlenRest', 'Ion', 'DereddenedFlux']].copy()\n",
    "                main_df.rename(columns={'DereddenedFlux': f'DereddenedFlux_{full_file_name}'}, inplace=True)\n",
    "            else:\n",
    "                # Ana DataFrame'de 'WlenRest' ve 'Ion' sütunlarına göre birleştirme yap\n",
    "                main_df = main_df.merge(sheet_data[['WlenRest', 'Ion', 'DereddenedFlux']],\n",
    "                                        on=['WlenRest', 'Ion'],\n",
    "                                        how='outer',\n",
    "                                        suffixes=('', f'_{full_file_name}'))\n",
    "\n",
    "# NaN değerleri '-' ile değiştir\n",
    "main_df.fillna('-', inplace=True)\n",
    "\n",
    "# 'WlenRest' sütununa göre küçükten büyüğe sırala\n",
    "main_df.sort_values('WlenRest', inplace=True)\n",
    "\n",
    "# Excel dosyasına ekleyeceğimiz sayfa adı\n",
    "new_sheet_name = 'DereddenedFlux_Tablo'\n",
    "\n",
    "# Yeni bir Excel dosyası oluştur\n",
    "output_excel_file_path = '/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/sigma_5/bilgiislem/deneme/DereddebFluxtablo.xlsx'\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='openpyxl') as writer:\n",
    "    main_df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "print(f\"Merged, sorted data has been successfully added to the sheet {new_sheet_name} in the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "\n",
    "# Klasördeki tüm FITS dosyalarını al\n",
    "fits_folder_path = '/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/neat_out/'\n",
    "fits_files = [file for file in os.listdir(fits_folder_path) if file.endswith('.fits')]\n",
    "\n",
    "# Boş bir DataFrame oluştur\n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "# Her bir FITS dosyasını işle\n",
    "for fits_file in fits_files:\n",
    "    fits_path = os.path.join(fits_folder_path, fits_file)\n",
    "\n",
    "    with fits.open(fits_path) as hdul:\n",
    "        # İlgili HDU'ya eriş\n",
    "        results_hdu = hdul['RESULTS']\n",
    "        \n",
    "        # İlgilenilen sütunu seç (2. sütun, Python'da indeks 1'e denk gelir)\n",
    "        selected_data = results_hdu.data.field(1)\n",
    "        \n",
    "        # Pandas Series'e dönüştür\n",
    "        fits_data = pd.Series(selected_data, name=fits_file)\n",
    "        \n",
    "        # DataFrame'e ekle\n",
    "        final_data = pd.concat([final_data, fits_data], axis=1)\n",
    "\n",
    "# Verileri Excel dosyasına yaz\n",
    "excel_output_path = '/Users/nurullah/Desktop/galaxy_abudance/Uzak_Pc/sigma_5/bilgiislem/deneme/neat_out_hdul3.xlsx'\n",
    "final_data.to_excel(excel_output_path, index=False)\n",
    "\n",
    "print(f\"Data from FITS files has been successfully saved to {excel_output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271960d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
