{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f747678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GDPNE klasöründe bulunan alt klasörlerdeki fits dosyalarını tek bir klasöre kaydetme ###\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def klasorleri_birlestir(ana_klasor, hedef_klasor):\n",
    "    if not os.path.exists(hedef_klasor):\n",
    "        os.makedirs(hedef_klasor)\n",
    "\n",
    "    for root, dirs, files in os.walk(ana_klasor):\n",
    "        for file in files:\n",
    "            if file.endswith('.fits'):\n",
    "                dosya_yolu = os.path.join(root, file)\n",
    "                shutil.copy2(dosya_yolu, hedef_klasor)\n",
    "\n",
    "    print(f'Tüm .fits dosyaları {hedef_klasor} klasörüne kopyalandı.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ana_klasor = \"/media/tbtk122f122/Expansion/HASH/GPNE/\"  # Ana klasörünüzün yolunu belirtin\n",
    "    cikti_dosyasi = \"/media/tbtk122f122/Expansion/HASH/tümtayflar/\"  # Çıktı dosyasının adını ve yolunu belirtin\n",
    "\n",
    "    klasorleri_birlestir(ana_klasor, cikti_dosyasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d44f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "## alfa programını çalıştırdık ###\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "fits_folder = '/media/tbtk122f122/Expansion/HASH/tümtayflar/'\n",
    "output_txt_filename = '/media/tbtk122f122/Expansion/HASH/sigma5alfaçıktı.txt'\n",
    "\n",
    "# fits dosyalarını işle\n",
    "fits_files = [f for f in os.listdir(fits_folder) if f.endswith('.fits')]\n",
    "\n",
    "# Dosyayı temizle veya oluştur\n",
    "with open(output_txt_filename, 'w') as output_file:\n",
    "    output_file.write(\"ALFA Program Çıktıları:\\n\\n\")\n",
    "\n",
    "# ALFA programını çalıştır ve çıktıları dosyaya yaz\n",
    "for fits_file in fits_files:\n",
    "    fits_path = os.path.join(fits_folder, fits_file)\n",
    "    \n",
    "    # alfa komutunu subprocess ile çağır ve çıktıları dosyaya yönlendir\n",
    "    result = subprocess.run(['alfa', fits_path, '-dl', '5', '-of', 'text'], capture_output=True, text=True)\n",
    "    \n",
    "    # Çıktıları dosyaya ekleyin\n",
    "    with open(output_txt_filename, 'a') as output_file:\n",
    "        output_file.write(f\"{'='*40}\\n{fits_file} dosyasının Çıktısı:\\n\\n\")\n",
    "        output_file.write(result.stdout)\n",
    "        output_file.write('\\n\\n')\n",
    "\n",
    "print(f\"Çıktılar {output_txt_filename} dosyasına kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lines çıktılarında neat çalıştırmak için düzenleme yaptık ###\n",
    "\n",
    "import os\n",
    "\n",
    "def düzenle_ve_kaydet(girdi_dosya, çıktı_dosya):\n",
    "    with open(girdi_dosya, 'r') as girdi, open(çıktı_dosya, 'w') as çıktı:\n",
    "        satırlar = girdi.readlines()\n",
    "\n",
    "        # '#' işareti ile başlayan tüm satırları atla\n",
    "        satırlar = [satır for satır in satırlar if not satır.startswith('#')]\n",
    "\n",
    "        # Satırları boşluklara göre ayır ve sadece 2. 3. ve 4. sütunları al\n",
    "        for satır in satırlar:\n",
    "            sütunlar = satır.split()\n",
    "            düzenlenmiş_satır = ' '.join(sütunlar[1:4])\n",
    "            \n",
    "            # Yeni satırı çıktı dosyasına yaz\n",
    "            çıktı.write(düzenlenmiş_satır + '\\n')\n",
    "\n",
    "# İlk satırı silme fonksiyonu\n",
    "def ilk_satırı_sil_ve_kaydet(çıktı_dosya):\n",
    "    with open(çıktı_dosya, 'r') as dosya:\n",
    "        satırlar = dosya.readlines()\n",
    "\n",
    "    # İlk satırı sil\n",
    "    satırlar = satırlar[1:]\n",
    "\n",
    "    # Düzenlenmiş dosyayı tekrar yaz\n",
    "    with open(çıktı_dosya, 'w') as dosya:\n",
    "        dosya.writelines(satırlar)\n",
    "\n",
    "# Klasördeki tüm dosyaları işleyen kod\n",
    "girdi_klasörü = '/media/tbtk122f122/Expansion/HASH/lines/'\n",
    "çıktı_klasörü = '/media/tbtk122f122/Expansion/HASH/neat_girdi/'\n",
    "\n",
    "# Çıktı klasörünü oluştur\n",
    "if not os.path.exists(çıktı_klasörü):\n",
    "    os.makedirs(çıktı_klasörü)\n",
    "\n",
    "# Klasördeki tüm dosyaları işle\n",
    "for dosya_adı in os.listdir(girdi_klasörü):\n",
    "    if dosya_adı.endswith(\"_lines\"):\n",
    "        girdi_dosya_yolu = os.path.join(girdi_klasörü, dosya_adı)\n",
    "        çıktı_dosya_yolu = os.path.join(çıktı_klasörü, dosya_adı)\n",
    "\n",
    "        # Dosyayı düzenle ve kaydet\n",
    "        düzenle_ve_kaydet(girdi_dosya_yolu, çıktı_dosya_yolu)\n",
    "        \n",
    "        # İlk satırı sil ve kaydet\n",
    "        ilk_satırı_sil_ve_kaydet(çıktı_dosya_yolu)\n",
    "\n",
    "print(\"Tüm dosyalar düzenlendi ve kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836438b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### neat programını çalıştırdık ####\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "fits_folder = '/media/tbtk122f122/Expansion/HASH/neat_girdi/'\n",
    "neat_output_folder = '/media/tbtk122f122/Expansion/HASH/neat_girdi/'\n",
    "output_txt_filename = '/media/tbtk122f122/Expansion/HASH/neat_girdi/sigma5neatçıktı.txt'\n",
    "\n",
    "# Dosyayı temizle veya oluştur\n",
    "with open(output_txt_filename, 'w') as output_file:\n",
    "    output_file.write(\"NEAT Program Çıktıları:\\n\\n\")\n",
    "\n",
    "# NEAT programını çalıştır ve çıktıları dosyaya yaz\n",
    "for fits_file in os.listdir(fits_folder):\n",
    "    if fits_file.endswith('_lines'):\n",
    "        fits_path = os.path.join(fits_folder, fits_file)\n",
    "        \n",
    "        # neat komutunu subprocess ile çağır ve çıktıları dosyaya yönlendir\n",
    "        #neat_output_path = os.path.join(neat_output_folder, fits_file.replace('.txt', '_neat.txt'))\n",
    "        result = subprocess.run(['neat', '-i', fits_path, '-n', '10000', '-u', '10000'], capture_output=True, text=True)\n",
    "        \n",
    "        # Çıktıları dosyaya ekleyin\n",
    "        with open(output_txt_filename, 'a') as output_file:\n",
    "            output_file.write(f\"{'='*40}\\n{fits_file} dosyasının NEAT Çıktısı:\\n\\n\")\n",
    "            output_file.write(result.stdout)\n",
    "            output_file.write('\\n\\n')\n",
    "\n",
    "print(f\"NEAT Çıktılar {output_txt_filename} dosyasına kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c502c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HDUL OKUMA ######\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "# Specify the path to your FITS file\n",
    "fits_file_path = '/media/tbtk122f122/Expansion/HASH/neat_out/2dF_Mar2007_PNG354.94-02.86F_id3152.fits_lines.fits'\n",
    "# Open the FITS file\n",
    "with fits.open(fits_file_path) as hdul:\n",
    "    # Access the data in the FITS file\n",
    "    primary_hdu = hdul[2]\n",
    "    data = primary_hdu.data\n",
    "    \n",
    "with fits.open(fits_file_path) as hdul:\n",
    "    hdul.info()\n",
    "\n",
    "    # Print the transposed data\n",
    "    print(\"\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db33b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### HER FİTS DOSYASI İÇİN BİR SAYFADA LİNES ÇIKTILARINI EXCELE KAYDETME  ####\n",
    "\n",
    "\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Dizin içindeki tüm FITS dosyalarını al\n",
    "fits_directory = '/media/tbtk122f122/Expansion/HASH/neat_out/'\n",
    "fits_file_paths = [os.path.join(fits_directory, file) for file in sorted(os.listdir(fits_directory)) if file.endswith('.fits')]\n",
    "\n",
    "# Excel dosyalarının kaydedileceği dizin\n",
    "output_directory = '/media/tbtk122f122/Expansion/HASH/excel/'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Her 50 FITS dosyası için ayrı bir Excel dosyası oluştur\n",
    "batch_size = 50\n",
    "for i in range(0, len(fits_file_paths), batch_size):\n",
    "    batch_fits_files = fits_file_paths[i:i + batch_size]\n",
    "\n",
    "    # Excel dosyasının ismini belirle\n",
    "    excel_file_name = f'batch_{i // batch_size + 1}.xlsx'\n",
    "    excel_file_path = os.path.join(output_directory, excel_file_name)\n",
    "\n",
    "    # Her FITS dosyası için döngü\n",
    "    with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:\n",
    "        for fits_file_path in batch_fits_files:\n",
    "            # Open the FITS file\n",
    "            with fits.open(fits_file_path) as hdul:\n",
    "                # Access the data and header of the LINES BinTableHDU (hdul[2])\n",
    "                data = hdul[1].data\n",
    "\n",
    "                # Convert the FITS data to a pandas DataFrame\n",
    "                df = pd.DataFrame(data)\n",
    "\n",
    "                # Sadece belirtilen sütunları seç\n",
    "                selected_columns = ['WlenRest', 'Flux', 'Uncertainty', 'Ion', 'DereddenedFlux', 'DereddenedFluxLo', 'DereddenedFluxHi']\n",
    "                df_selected = df[selected_columns]\n",
    "\n",
    "                # Negatif ve sıfıra eşit olan değerlere sahip satırları filtrele ve sil\n",
    "                df_selected = df_selected[df_selected['Flux'] > 0.01]\n",
    "\n",
    "                # Sayfa adını dosya isminin _id karakterinden sonrasına ayarla\n",
    "                #sheet_name = os.path.basename(fits_file_path).split('_id')[1]\n",
    "                sheet_name = os.path.basename(fits_file_path)[:30]\n",
    "\n",
    "                # Verileri içeren DataFrame'i yeni bir sayfada kaydet\n",
    "                df_selected.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"Data has been successfully exported to {excel_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f192d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HER FİTS DOSYASI İÇİN BİR SAYFADA LİNES ÇIKTILARINDAN FLUX DEĞERLERİNDEN TABLO OLUŞTURMA KAYDETME  ####\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Excel dosyalarının bulunduğu klasörün tam yolu\n",
    "excel_folder_path = '/media/tbtk122f122/Expansion/HASH/excel/'\n",
    "\n",
    "# Tüm Excel dosyalarını al\n",
    "excel_files = [os.path.join(excel_folder_path, file) for file in sorted(os.listdir(excel_folder_path)) if file.endswith('.xlsx')]\n",
    "\n",
    "# Birleştirilecek verileri tutacak ana DataFrame'i oluştur\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "# Her Excel dosyası için döngü\n",
    "for excel_file_path in excel_files:\n",
    "    # Excel dosyasını oku\n",
    "    df = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "\n",
    "    # Her sayfa için döngü\n",
    "    for sheet_name, sheet_data in df.items():\n",
    "        # 'WlenRest', 'Ion', 'Flux', 'Uncertainty' sütunlarını içeren sayfaları seç\n",
    "        #if all(col in sheet_data.columns for col in ['WlenRest', 'Ion', 'Flux', 'Uncertainty']):\n",
    "        if all(col in sheet_data.columns for col in ['WlenRest', 'Ion', 'Flux']):\n",
    "            # Eğer ana DataFrame boşsa, direkt ekle\n",
    "            if main_df.empty:\n",
    "                #main_df = sheet_data[['WlenRest', 'Ion', 'Flux', 'Uncertainty']].copy()\n",
    "                main_df = sheet_data[['WlenRest', 'Ion', 'Flux']].copy()\n",
    "                #main_df.rename(columns={'Flux': f'Flux_{sheet_name}', 'Uncertainty': f'Uncertainty_{sheet_name}'}, inplace=True)\n",
    "                main_df.rename(columns={'Flux': f'Flux_{sheet_name}'}, inplace=True)\n",
    "            else:\n",
    "                # Ana DataFrame'de 'WlenRest' ve 'Ion' sütunlarına göre birleştirme yap\n",
    "                #main_df = main_df.merge(sheet_data[['WlenRest', 'Ion', 'Flux', 'Uncertainty']],\n",
    "                main_df = main_df.merge(sheet_data[['WlenRest', 'Ion', 'Flux']],\n",
    "                                        on=['WlenRest', 'Ion'],\n",
    "                                        how='outer',\n",
    "                                        suffixes=('', f'_{sheet_name}'))\n",
    "\n",
    "# NaN değerleri '-' ile değiştir\n",
    "main_df.fillna('-', inplace=True)\n",
    "\n",
    "# 'WlenRest' sütununa göre küçükten büyüğe sırala\n",
    "main_df.sort_values('WlenRest', inplace=True)\n",
    "\n",
    "# Excel dosyasına ekleyeceğimiz sayfa adı\n",
    "new_sheet_name = 'Flux_Tablo'\n",
    "\n",
    "# Yeni bir Excel dosyası oluştur\n",
    "output_excel_file_path = '/media/tbtk122f122/Expansion/HASH/Fluxtablo.xlsx'\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='openpyxl') as writer:\n",
    "    main_df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "print(f\"Merged, sorted data has been successfully added to the sheet {new_sheet_name} in the Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HER FİTS DOSYASI İÇİN BİR SAYFADA LİNES ÇIKTILARINDAN DEREDDENED FLUX DEĞERLERİNDEN TABLO OLUŞTURMA KAYDETME  ####\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Excel dosyalarının bulunduğu klasörün tam yolu\n",
    "excel_folder_path = '/media/tbtk122f122/Expansion/HASH/excel/'\n",
    "\n",
    "# Tüm Excel dosyalarını al\n",
    "excel_files = [os.path.join(excel_folder_path, file) for file in sorted(os.listdir(excel_folder_path)) if file.endswith('.xlsx')]\n",
    "\n",
    "# Birleştirilecek verileri tutacak ana DataFrame'i oluştur\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "# Her Excel dosyası için döngü\n",
    "for excel_file_path in excel_files:\n",
    "    # Excel dosyasını oku\n",
    "    df = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "\n",
    "    # Her sayfa için döngü\n",
    "    for sheet_name, sheet_data in df.items():\n",
    "        # 'WlenRest', 'Ion', 'Flux', 'Uncertainty' sütunlarını içeren sayfaları seç\n",
    "        #if all(col in sheet_data.columns for col in ['WlenRest', 'Ion', 'Flux', 'Uncertainty']):\n",
    "        if all(col in sheet_data.columns for col in ['WlenRest', 'Ion', 'DereddenedFlux']):\n",
    "            # Eğer ana DataFrame boşsa, direkt ekle\n",
    "            if main_df.empty:\n",
    "                #main_df = sheet_data[['WlenRest', 'Ion', 'Flux', 'Uncertainty']].copy()\n",
    "                main_df = sheet_data[['WlenRest', 'Ion', 'DereddenedFlux']].copy()\n",
    "                #main_df.rename(columns={'Flux': f'Flux_{sheet_name}', 'Uncertainty': f'Uncertainty_{sheet_name}'}, inplace=True)\n",
    "                main_df.rename(columns={'DereddenedFlux': f'DereddenedFlux_{sheet_name}'}, inplace=True)\n",
    "            else:\n",
    "                # Ana DataFrame'de 'WlenRest' ve 'Ion' sütunlarına göre birleştirme yap\n",
    "                #main_df = main_df.merge(sheet_data[['WlenRest', 'Ion', 'Flux', 'Uncertainty']],\n",
    "                main_df = main_df.merge(sheet_data[['WlenRest', 'Ion', 'DereddenedFlux']],\n",
    "                                        on=['WlenRest', 'Ion'],\n",
    "                                        how='outer',\n",
    "                                        suffixes=('', f'_{sheet_name}'))\n",
    "\n",
    "# NaN değerleri '-' ile değiştir\n",
    "main_df.fillna('-', inplace=True)\n",
    "\n",
    "# 'WlenRest' sütununa göre küçükten büyüğe sırala\n",
    "main_df.sort_values('WlenRest', inplace=True)\n",
    "\n",
    "# Excel dosyasına ekleyeceğimiz sayfa adı\n",
    "new_sheet_name = 'DereddenedFlux_Tablo'\n",
    "\n",
    "# Yeni bir Excel dosyası oluştur\n",
    "output_excel_file_path = '/media/tbtk122f122/Expansion/HASH/DereddenedFluxtablo.xlsx'\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='openpyxl') as writer:\n",
    "    main_df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "print(f\"Merged, sorted data has been successfully added to the sheet {new_sheet_name} in the Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466866a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########.  neat_hdul3_çıktısını her bir fits dosyası için sütun oluşturarak excel dosyasına kaydediyor. ########\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "\n",
    "# Klasördeki tüm FITS dosyalarını al\n",
    "fits_folder_path = '/media/tbtk122f122/Expansion/HASH/neat_out/'\n",
    "fits_files = [file for file in os.listdir(fits_folder_path) if file.endswith('.fits')]\n",
    "\n",
    "# Boş bir DataFrame oluştur\n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "# Her bir FITS dosyasını işle\n",
    "for fits_file in fits_files:\n",
    "    fits_path = os.path.join(fits_folder_path, fits_file)\n",
    "\n",
    "    with fits.open(fits_path) as hdul:\n",
    "        # İlgili HDU'ya eriş\n",
    "        results_hdu = hdul['RESULTS']\n",
    "        \n",
    "        # İlgilenilen sütunu seç (2. sütun, Python'da indeks 1'e denk gelir)\n",
    "        selected_data = results_hdu.data.field(1)\n",
    "        \n",
    "        # Pandas Series'e dönüştür\n",
    "        fits_data = pd.Series(selected_data, name=fits_file)\n",
    "        \n",
    "        # DataFrame'e ekle\n",
    "        final_data = pd.concat([final_data, fits_data], axis=1)\n",
    "\n",
    "# Verileri Excel dosyasına yaz\n",
    "excel_output_path = '/media/tbtk122f122/Expansion/HASH/neat_results.xlsx'\n",
    "final_data.to_excel(excel_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56586fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
